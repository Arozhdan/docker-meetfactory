name: STAGING_FETCH_DATA
on:
  workflow_dispatch:
    inputs:
      source:
        description: "From: 'p: Production server' | 'f: File pushed from local machine'"     
        required: true
        default: 'p'
jobs:
  Fetch_db:
    runs-on: [self-hosted, staging worker]
    steps:
      - uses: actions/checkout@v2
        with:
          clean: false

      - name: Copy production db
        if: github.event.inputs.source != 'f'
        run: |
          docker exec -t ${{github.event.repository.name}}_postgres_prod_1 pg_dump -c -U  ${{secrets.POSTGRES_USER}}  ${{secrets.POSTGRES_DB}} > /backup/dump_`date +%d-%m-%Y"_"%H_%M_%S`.sql
          docker exec -t ${{github.event.repository.name}}_postgres_prod_1 pg_dump -c -U  ${{secrets.POSTGRES_USER}}  ${{secrets.POSTGRES_DB}} > /backup/latest.sql

      - name: Clear staging db
        run: |
          docker exec -t ${{github.event.repository.name}}_postgres_1 psql -U strapi -d strapi -c "
          DO \$\$ 
            DECLARE 
              r RECORD;
            BEGIN
            FOR r IN 
              (
                SELECT table_name
                FROM information_schema.tables 
                WHERE table_schema=current_schema()
              ) 
            LOOP
               EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.table_name) || ' CASCADE';
            END LOOP;
          END \$\$ ;
          "
      - name: Insert data into staging db from prod db
        if: github.event.inputs.source != 'f'
        run: cat /backup/latest.sql | docker exec -i ${{github.event.repository.name}}_postgres_1 psql -U strapi
     
      - name: Insert data into staging db from file
        if: github.event.inputs.source == 'f'
        run: cat /backup/local.sql | docker exec -i ${{github.event.repository.name}}_postgres_1 psql -U strapi